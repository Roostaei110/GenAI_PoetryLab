{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WxSr0psQp1_G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import time\n",
        "import inspect\n",
        "from dataclasses import dataclass\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bolbolzaban/gpt2-persian')\n",
        "\n",
        "def tokenize(doc):\n",
        "    tokens = tokenizer.encode(doc, add_special_tokens=False)\n",
        "    tokens_np = np.array(tokens)\n",
        "    tokens_np_uint16 = tokens_np.astype(np.uint16)\n",
        "    return tokens_np_uint16\n",
        "\n",
        "\n",
        "def read_data(docs):\n",
        "    lines = []\n",
        "    i=0\n",
        "    while i<len(docs)-1:\n",
        "      mesr1 = docs[i].replace('\\n', '')\n",
        "      mesr2 = docs[i+1].replace('\\n', '')\n",
        "\n",
        "      if len(mesr1)==0:\n",
        "        i+=1\n",
        "        continue\n",
        "\n",
        "      if mesr1.isspace()  or mesr1==\" \" or len(mesr1)<4 or mesr2.isspace()  or mesr2==\" \" or len(mesr2)<4:\n",
        "        print(\"there is a problem, please check it.\")\n",
        "        i+=1\n",
        "        continue\n",
        "      line = ' [BOM] '+ mesr1 +' [BOM] '+ mesr2 +'[EOS]'+'\\n'\n",
        "      lines.append(line)\n",
        "\n",
        "      i+=2\n",
        "    return lines\n",
        "\n"
      ],
      "metadata": {
        "id": "WnEZKy5Bp4A1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "data = []\n",
        "def clear_text(address):\n",
        "  fp = open(address)\n",
        "  list_sent = fp.readlines()\n",
        "  for i in list_sent[1:]:\n",
        "    i = i.replace('\\u200c', ' ')\n",
        "    i = i.replace('    ', ' ')\n",
        "    i = i.replace('   ', ' ')\n",
        "    i = i.replace('  ', ' ')\n",
        "    data.append(i)\n",
        "  return data\n",
        "\n",
        "\n",
        "data1 = clear_text('/content/eynolghozat_cleaned.txt')\n",
        "\n",
        "data = data1\n",
        "data[0:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXbsN6W3p74-",
        "outputId": "841521f7-0b7d-4ee7-809b-b704c1acf0c8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ز رویت می کند روشن خیالت چشم موسی را\\n',\n",
              " 'سحرگه عزم بستان کن صبوحی در گلستان کن\\n',\n",
              " 'به بلبل می برد از گل صبا صد گونه بشری را\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "clean_data = data\n",
        "print(\"cleaned lines\", len(clean_data))\n",
        "\n",
        "docs_beit = read_data(clean_data)\n",
        "print(\"number of beits :\", len(docs_beit))\n",
        "docs_beit[0:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg3tKe2UrtnA",
        "outputId": "fee1b7fe-a3f7-4221-dbf1-3c79eaae0844"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cleaned lines 190423\n",
            "there is a problem, please check it.\n",
            "there is a problem, please check it.\n",
            "there is a problem, please check it.\n",
            "there is a problem, please check it.\n",
            "there is a problem, please check it.\n",
            "number of beits : 95209\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' [BOM] ز رویت می کند روشن خیالت چشم موسی را [BOM] سحرگه عزم بستان کن صبوحی در گلستان کن[EOS]\\n',\n",
              " ' [BOM] به بلبل می برد از گل صبا صد گونه بشری را [BOM] کسی با شوق روحانی نخواهد ذوق جسمانی[EOS]\\n',\n",
              " ' [BOM] برای گلبن وصلش رها کن من و سلوی را [BOM] گر از پرده برون آیی و ما را روی بنمایی[EOS]\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split validation and train\n",
        "len_train = int(len(docs_beit)*0.8)\n",
        "data_train = docs_beit[0:len_train]\n",
        "data_val = docs_beit[len_train:]\n",
        "print(f\"number of train is {len(x_train)} ----- number of validation is {len(x_val)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSexQTe0rsKv",
        "outputId": "a62ce14e-6652-4907-bc96-ea7c218b1cde"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of train is 76168 ----- number of validation is 19042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DataLoaderLite:\n",
        "    def __init__(self, B, T, data, process_rank,tokenizer):\n",
        "        self.B = B\n",
        "        self.T = T\n",
        "        self.process_rank = process_rank\n",
        "        self.data = data  # full dataset of beit\n",
        "        self.tokenizer = tokenizer  # A function to tokenize sentences\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_position = self.B * self.T * self.process_rank\n",
        "        self.indices = list(range(len(self.data)))  # Indices of sentences\n",
        "        print(len(self.data))\n",
        "\n",
        "    def next_batch(self):\n",
        "        B, T = self.B, self.T\n",
        "        x_batch, y_batch = [], []\n",
        "        tokens_batch = []\n",
        "\n",
        "        while len(tokens_batch) < B * T + 1:  # Ensure we have enough tokens for B*T+1\n",
        "            if self.current_position >= len(self.indices):\n",
        "                self.reset()  # Shuffle and start over if we've processed all sentences\n",
        "\n",
        "            sentence_idx = self.indices[self.current_position]\n",
        "            sentence = self.data[sentence_idx]\n",
        "            tokens = self.tokenizer(sentence)  # Tokenize the current sentence\n",
        "            tokens_batch.extend(tokens)\n",
        "\n",
        "            self.current_position += 1\n",
        "\n",
        "        tokens_batch = tokens_batch[:B * T + 1]\n",
        "\n",
        "        # Create x_batch and y_batch\n",
        "        x_batch = []\n",
        "        y_batch = []\n",
        "\n",
        "        for i in range(B):\n",
        "            start_idx = i * T\n",
        "            x_batch.append(tokens_batch[start_idx:start_idx + T])\n",
        "            y_batch.append(tokens_batch[start_idx + 1:start_idx + T + 1])\n",
        "\n",
        "        x_tensor = torch.tensor(x_batch, dtype=torch.long)\n",
        "        y_tensor = torch.tensor(y_batch, dtype=torch.long)\n",
        "        return x_tensor, y_tensor\n"
      ],
      "metadata": {
        "id": "IUsOTFHDqYDy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_train = DataLoaderLite(B=3, T=15, process_rank=0, data= data_train, tokenizer=tokenize)\n",
        "dataloader_val = DataLoaderLite(B=2, T=20, process_rank=0, data= data_val, tokenizer=tokenize)\n",
        "\n",
        "x_batch, y_batch = dataloader_train.next_batch()\n",
        "print(x_batch)\n",
        "print(y_batch)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpJujFypqecs",
        "outputId": "22800fd4-ca91-4f74-be2f-a4999efac1e3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76167\n",
            "19042\n",
            "tensor([[    7,   105,  4704,    52,   124,   673,  8680,   246,  2147,    53,\n",
            "             7, 19956,  3612,  4140,   335],\n",
            "        [20198,    46,  2393,   335,     9,     7,    48,  3245,    52,   689,\n",
            "            50,   235,  3546,   606,   393],\n",
            "        [ 4474,    53,     7,   269,    57,  2192,  1948,   906,  3783,  5476,\n",
            "             9,     7,    62, 12260, 18407]])\n",
            "tensor([[  105,  4704,    52,   124,   673,  8680,   246,  2147,    53,     7,\n",
            "         19956,  3612,  4140,   335, 20198],\n",
            "        [   46,  2393,   335,     9,     7,    48,  3245,    52,   689,    50,\n",
            "           235,  3546,   606,   393,  4474],\n",
            "        [   53,     7,   269,    57,  2192,  1948,   906,  3783,  5476,     9,\n",
            "             7,    62, 12260, 18407,  1702]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(x_batch[0]))\n",
        "print(tokenizer.decode(y_batch[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsklonsVvJpd",
        "outputId": "f44ddc7d-618d-47c3-c535-b8f6c3edabec"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BOM] ز رویت می کند روشن خیالت چشم موسی را[BOM] سحرگه عزم بستان کن\n",
            "ز رویت می کند روشن خیالت چشم موسی را[BOM] سحرگه عزم بستان کن صبوحی\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DpU6S_Osyfop"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}